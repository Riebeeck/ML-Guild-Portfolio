{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfertraining facefinder\n",
    "# eye_cascade = cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init classifier\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "# This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs: \n",
    "# 32 Random filters each of size 3x3 -- input shape of 64x64 RGB\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Max Pooling is typically added to CNN after individual convolutional layers\n",
    "# It basically scales down the number of pixels in the output of the convo. layers by some factor (in the case by factor of 2[half])\n",
    "classifier.add(Flatten())\n",
    "# this essentially turns our input shape into a flattened vector of shape 64*64*3 = 12288 \n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "# First activatio layer (hidden) applies ReLU and transforms output dimensionality of 128 in the resulting output space\n",
    "# ReLU (Rectified Linear Unit) function when applied it will convert all negative numbers to 0 or positive.\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# Second hidden layer \n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.load_weights(\"classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# init the labels dict in a weird way since i dont know a shortcut(this piece comes from model training)\n",
    "# ImageDataGenerator - Generates batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./pics/',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "\n",
    "labels = dict((value, key) for key, value in training_set.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # number specifies the camera which to use 0 = my only webcam\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w,y+h), (255, 0, 0), 2) # (image, start bottom L, end top R, color, line-width)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = img[y:y+h,x:x+w]\n",
    "        \n",
    "        pred_image = roi_color\n",
    "        pred_image = np.stack((np.dot(roi_color[...,:3], [1/255, 1/255, 1/255]),)*3, -1)\n",
    "        pred_image = cv2.resize(pred_image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "        # test_image = pred_image\n",
    "        pred_image = np.expand_dims(pred_image, axis = 0)\n",
    "        result = classifier.predict(pred_image)\n",
    "        cv2.putText(img,labels.get(round(result[0][0])),(x+10, y+30), 0, 1, (0, 0, 255),2)\n",
    "        \n",
    "        # eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        # for (ex, ey, ew, eh) in eyes:\n",
    "        #     cv2.rectangle(roi_color, (ex, ey), (ex+ew,ey+eh), (0, 255, 0), 2)\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:   \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
